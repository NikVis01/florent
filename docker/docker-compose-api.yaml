services:
  florent-api:
    build:
      context: ..
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gpt-4-turbo-preview}
      - BGE_M3_URL=${BGE_M3_URL:-http://bge-m3:8080}
    depends_on:
      bge-m3:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ../src:/app/src:ro
      - ../src/data:/app/src/data:ro
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  bge-m3:
    image: mdelapenya/bge-m3:0.3.13-567m
    ports:
      - "8080:8080"
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:8080/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
